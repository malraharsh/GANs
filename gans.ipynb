{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_channels, features): # disc features\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, features, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features, features*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "                        \n",
    "            nn.Conv2d(features*2, features*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features*4, features*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(features*8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, noise_channels, img_channels, features): # gen features\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_channels, features * 16, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(features*16),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(features * 16, features*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features*8),\n",
    "            nn.ReLU(True),\n",
    "                        \n",
    "            nn.ConvTranspose2d(features*8, features*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(features*4, features*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(features*2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(features*2, img_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "#         if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "#             nn.init.normal_(m.weight_data, 0.0, 0.02)\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    batch, channels, height, width = 8, 3, 64, 64\n",
    "    features = 8\n",
    "    noise_dim = 100\n",
    "    x = torch.randn(batch, channels, height, width)\n",
    "    disc = Discriminator(channels, features)\n",
    "    assert disc(x).shape == (batch, 1, 1, 1), 'Failed'\n",
    "    z = torch.randn(batch, noise_dim, 1, 1)\n",
    "    gen = Generator(noise_dim, channels, features)\n",
    "    assert gen(z).shape == (batch, channels, height, width), 'Failed'\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "LEARNING_RATE = 2e-4\n",
    "IMG_SIZE = 64\n",
    "NOISE_DIM = 100\n",
    "FEATURES_DISC = 64\n",
    "FEATURES_GEN = 64\n",
    "IMG_CHANNELS = 1\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-c650c0b86aff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[0;32m     72\u001b[0m                                ' You can use download=True to download it')\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5] * IMG_CHANNELS, [0.5] * IMG_CHANNELS)\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('datasets/', transform=transform, download=False)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = Generator(NOISE_DIM, IMG_CHANNELS, FEATURES_GEN).to(device)\n",
    "disc_model = Discriminator(IMG_CHANNELS, FEATURES_DISC).to(device)\n",
    "gen, disc = gen_model, disc_model\n",
    "initialize_weights(gen_model)\n",
    "initialize_weights(disc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BETAS = (0.5, 0.999)\n",
    "opt_gen = optim.Adam(gen_model.parameters(), lr=LEARNING_RATE, betas=BETAS)\n",
    "opt_disc = optim.Adam(disc_model.parameters(), lr=LEARNING_RATE, betas=BETAS)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f'logs/real')\n",
    "writer_fake = SummaryWriter(f'logs/fake')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.train()\n",
    "disc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (real, _) in enumerate(dataloader):\n",
    "    real = real.to(device)\n",
    "    noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n",
    "    fake = gen(noise)\n",
    "    \n",
    "    # Train Disc\n",
    "    disc_real = disc(real).reshape(-1)\n",
    "    loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "    disc_fake = disc(fake.detach()).reshape(-1)\n",
    "    loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "    loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "    disc.zero_grad()\n",
    "    loss_disc.backward()\n",
    "    opt_disc.step()\n",
    "    \n",
    "    # Train Gen\n",
    "    output = disc(fake)\n",
    "    loss_gen = criterion(output, torch.ones_like(output))\n",
    "    gen.zero_grad()\n",
    "    loss_gen.backward()\n",
    "    opt_gen.step()\n",
    "    \n",
    "    if batch_idx % 100 == 0:\n",
    "        print(f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "              Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake = gen(fixed_noise)\n",
    "            # take out (up to) 32 examples\n",
    "            img_grid_real = torchvision.utils.make_grid(\n",
    "                real[:32], normalize=True\n",
    "            )\n",
    "            img_grid_fake = torchvision.utils.make_grid(\n",
    "                fake[:32], normalize=True\n",
    "            )\n",
    "\n",
    "            writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "            writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
